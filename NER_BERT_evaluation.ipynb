{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_BERT_evaluation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debugk/NER_Covid19/blob/AddEval/NER_BERT_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwPcFVUs3UCq",
        "colab_type": "text"
      },
      "source": [
        "# Upload model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziSb3-jO1omp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "825a4adb-51d6-4ecd-eb56-2d9bf8d96a41"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgASLOWL2GXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "cb6374f1-9687-44e3-9213-14fd28992add"
      },
      "source": [
        "#install the amazing transformers package by huggingface\n",
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertConfig, BertForTokenClassification, AdamW\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 25.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 4.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 13.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 31.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 57.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=35a2ad9d893650253814e1992c878499ac9ae8023cbaf298e6e6ac2dfda8df49\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRSx1Z9I2KNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9598fad3-03ee-4ebf-adde-40ed5de8c459"
      },
      "source": [
        "## setup GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0rf427p14OE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c79e393b-8456-4f88-a5c2-e6c0eebf7818"
      },
      "source": [
        "output_dir = '/content/gdrive/My Drive/Covid19_data/model_save/'\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForTokenClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riez1qqn3aRT",
        "colab_type": "text"
      },
      "source": [
        "# Apply the model to a new sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEgUzaPH3NHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence=\"\"\"\n",
        "Safety and efficacy of intravenous bimagrumab in inclusion body myositis (RESILIENT): a randomised, double-blind, placebo-controlled phase 2b trial\\tBimagrumab showed a good safety profile, relative to placebo, in individuals with inclusion body myositis but did not improve 6MWD. The strengths of our study are that, to the best of our knowledge, it is the largest randomised controlled trial done in people with inclusion body myositis, and it provides important natural history data over 12 months.\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfQNhJyI3fnQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "18a04bee-e2fb-4134-c26d-d35fbfac9449"
      },
      "source": [
        "# first tokenize the text\n",
        "tokenized_sentence = tokenizer.encode( test_sentence, clean_text=False)\n",
        "test_input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
        "\n",
        "test_input_ids"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keyword arguments {'clean_text': False} not recognized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  3808,  1998, 21150,  1997, 26721,  8159,  3560, 12170,  2863,\n",
              "         16523, 12248,  2497,  1999, 10502,  2303,  2026, 20049,  7315,  1006,\n",
              "         24501, 18622,  4765,  1007,  1024,  1037,  6721,  5084,  1010,  3313,\n",
              "          1011,  6397,  1010,  2173,  5092,  1011,  4758,  4403,  1016,  2497,\n",
              "          3979, 12170,  2863, 16523, 12248,  2497,  3662,  1037,  2204,  3808,\n",
              "          6337,  1010,  5816,  2000,  2173,  5092,  1010,  1999,  3633,  2007,\n",
              "         10502,  2303,  2026, 20049,  7315,  2021,  2106,  2025,  5335,  1020,\n",
              "          2213, 21724,  1012,  1996, 20828,  1997,  2256,  2817,  2024,  2008,\n",
              "          1010,  2000,  1996,  2190,  1997,  2256,  3716,  1010,  2009,  2003,\n",
              "          1996,  2922,  6721,  5084,  4758,  3979,  2589,  1999,  2111,  2007,\n",
              "         10502,  2303,  2026, 20049,  7315,  1010,  1998,  2009,  3640,  2590,\n",
              "          3019,  2381,  2951,  2058,  2260,  2706,  1012,   102]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00c2UV8rl8Xi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a291ce2-4daf-4d8b-a00a-fc80acbe946b"
      },
      "source": [
        "tokenizer.encode(\" \")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GCxQdbS3o9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "# run the sentence through the model\n",
        "with torch.no_grad():\n",
        "    output = model(test_input_ids)\n",
        "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONV44X3tFkOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_values = ['B-Organization', 'I-Organization', 'B-ChemicalCompound', 'B-Drug', 'B-Disease', 'I-Drug', 'I-Gene', 'B-Virus', 'I-Phenotype', 'B-Gene', 'I-Virus', 'B-Phenotype', 'I-ChemicalCompound', 'B-Chemical', 'I-Disease', 'I-Chemical', 'O', 'PAD']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EUGm3tQ3r17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tag_values = ['B-Virus', 'B-Organization', 'I-Drug', 'B-Drug', 'O', 'I-Virus', 'B-Chemical', 'B-Disease', 'I-Disease', 'B-Gene', 'I-Organization', 'I-Chemical', 'I-ChemicalCompound', 'I-Gene', 'B-Phenotype', 'I-Phenotype', 'B-ChemicalCompound', 'PAD']\n",
        "# join bpe split tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(test_input_ids.to('cpu').numpy()[0])\n",
        "new_tokens, new_labels = [], []\n",
        "for token, label_idx in zip(tokens, label_indices[0]):\n",
        "    if token.startswith(\"##\"):\n",
        "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "    else:\n",
        "        new_labels.append(tag_values[label_idx])\n",
        "        new_tokens.append(token)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqr280Gw5Wgw",
        "colab_type": "text"
      },
      "source": [
        "entities\": [{\"entity\": \"SARS-CoV\", \"type\": \"Virus\", \"start\": 48, \"end\": 56}, {\"entity\": \"SARS-CoV\", \"type\": \"Virus\", \"start\": 445, \"end\": 453}, {\"entity\": \"SARS-CoV\", \"type\": \"Virus\", \"start\": 579, \"end\": 587}, {\"entity\": \"SARS-CoV\", \"type\": \"Virus\", \"start\": 675, \"end\": 683}, {\"entity\": \"SARS-CoV\", \"type\": \"Virus\", \"start\": 867, \"end\": 875}, {\"entity\": \"SARS-CoV\", \"type\": \"Virus\", \"start\": 986, \"end\": 994}, {\"entity\": \"SARS-CoV\", \"type\": \"Virus\", \"start\": 1325, \"end\": 1333}, {\"entity\": \"angiotensin-converting enzyme 2\", \"type\": \"Gene\", \"start\": 379, \"end\": 410}, {\"entity\": \"ACE2\", \"type\": \"Gene\", \"start\": 412, \"end\": 416}, {\"entity\": \"ACE2\", \"type\": \"Gene\", \"start\": 751, \"end\": 755}, {\"entity\": \"host protein\", \"type\": \"Gene\", \"start\": 423, \"end\": 435}, {\"entity\": \"SARS-CoV-2\", \"type\": \"Virus\", \"start\": 61, \"end\": 71}, {\"entity\": \"SARS-CoV-2\", \"type\": \"Virus\", \"start\": 458, \"end\": 468}, {\"entity\": \"SARS-CoV-2\", \"type\": \"Virus\", \"start\": 592, \"end\": 602}, {\"entity\": \"SARS-CoV-2\", \"type\": \"Virus\", \"start\": 688, \"end\": 698}, {\"entity\": \"SARS-CoV-2\", \"type\": \"Virus\", \"start\": 879, \"end\": 889}, {\"entity\": \"SARS-CoV-2\", \"type\": \"Virus\", \"start\": 998, \"end\": 1008}, {\"entity\": \"SARS-CoV-2\", \"type\": \"Virus\", \"start\": 1338, \"end\": 1348}, {\"entity\": \"ACE2 gene\", \"type\": \"Gene\", \"start\": 487, \"end\": 496}, {\"entity\": \"coronaviruses\", \"type\": \"Virus\", \"start\": 1219, \"end\": 1232}, {\"entity\": \"host proteins\", \"type\": \"Gene\", \"start\": 1298, \"end\": 1311}]}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvWI-rMX4MaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8af33745-78a9-4a0c-db26-ecb66989aa49"
      },
      "source": [
        "for token, label in zip(new_tokens, new_labels):\n",
        "    print(\"{}\\t{}\".format(label, token))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\t[CLS]\n",
            "O\tsafety\n",
            "O\tand\n",
            "O\tefficacy\n",
            "O\tof\n",
            "O\tintravenous\n",
            "B-Gene\tbimagrumab\n",
            "O\tin\n",
            "B-Disease\tinclusion\n",
            "I-Disease\tbody\n",
            "I-Disease\tmyositis\n",
            "O\t(\n",
            "O\tresilient\n",
            "O\t)\n",
            "O\t:\n",
            "O\ta\n",
            "O\trandomised\n",
            "O\t,\n",
            "O\tdouble\n",
            "O\t-\n",
            "O\tblind\n",
            "O\t,\n",
            "O\tplacebo\n",
            "O\t-\n",
            "O\tcontrolled\n",
            "O\tphase\n",
            "O\t2b\n",
            "O\ttrial\n",
            "B-Gene\tbimagrumab\n",
            "O\tshowed\n",
            "O\ta\n",
            "O\tgood\n",
            "O\tsafety\n",
            "O\tprofile\n",
            "O\t,\n",
            "O\trelative\n",
            "O\tto\n",
            "O\tplacebo\n",
            "O\t,\n",
            "O\tin\n",
            "O\tindividuals\n",
            "O\twith\n",
            "B-Disease\tinclusion\n",
            "I-Disease\tbody\n",
            "I-Disease\tmyositis\n",
            "O\tbut\n",
            "O\tdid\n",
            "O\tnot\n",
            "O\timprove\n",
            "O\t6mwd\n",
            "O\t.\n",
            "O\tthe\n",
            "O\tstrengths\n",
            "O\tof\n",
            "O\tour\n",
            "O\tstudy\n",
            "O\tare\n",
            "O\tthat\n",
            "O\t,\n",
            "O\tto\n",
            "O\tthe\n",
            "O\tbest\n",
            "O\tof\n",
            "O\tour\n",
            "O\tknowledge\n",
            "O\t,\n",
            "O\tit\n",
            "O\tis\n",
            "O\tthe\n",
            "O\tlargest\n",
            "O\trandomised\n",
            "O\tcontrolled\n",
            "O\ttrial\n",
            "O\tdone\n",
            "O\tin\n",
            "O\tpeople\n",
            "O\twith\n",
            "B-Disease\tinclusion\n",
            "I-Disease\tbody\n",
            "I-Disease\tmyositis\n",
            "O\t,\n",
            "O\tand\n",
            "O\tit\n",
            "O\tprovides\n",
            "O\timportant\n",
            "O\tnatural\n",
            "O\thistory\n",
            "O\tdata\n",
            "O\tover\n",
            "O\t12\n",
            "O\tmonths\n",
            "O\t.\n",
            "O\t[SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfWK-wO0gUn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_to_dict(labels, tokens, sentence):\n",
        "    \"\"\"\n",
        "      labels:  python array, labels of one sentence\n",
        "      tokens:  python array\n",
        "      outdicts: a array of python dictionary\n",
        "      convert the given labels to outdicts\n",
        "    \"\"\"\n",
        "    outdicts = []\n",
        "\n",
        "    start_point = 0\n",
        "    end_point   = 0\n",
        "    pred_type   = None\n",
        "\n",
        "    # ignore the uppercase and lowercase\n",
        "    sentence_upper = sentence.upper()\n",
        "\n",
        "    for label, token in zip(labels, tokens):\n",
        "        token = token.upper()\n",
        "\n",
        "        if label.count('I-'):\n",
        "            if  label.replace('I-', '') != pred_type:\n",
        "                print(\"Unmatched B-type and I-type\")\n",
        "                raise  \n",
        "\n",
        "            end_point = sentence_upper.find(token, end_point) + len(token)\n",
        "        \n",
        "        else:\n",
        "            if end_point > start_point and pred_type:\n",
        "                entity = sentence[start_point:end_point]\n",
        "\n",
        "                outdicts += [{\"entity\": entity, \"type\": pred_type, \"start\": start_point, \"end\": end_point}]\n",
        "\n",
        "                # initial again \n",
        "                start_point = end_point\n",
        "                pred_type   = None\n",
        "\n",
        "            elif label.count('B-'):\n",
        "                pred_type   = label.replace('B-', '')\n",
        "                start_point = sentence_upper.find(token, end_point)\n",
        "                end_point   = start_point + len(token)  \n",
        "\n",
        "    return outdicts\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E0pc3FP7yP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "54732f5f-b665-424b-8054-4f34a03c5a3c"
      },
      "source": [
        "label_to_dict(new_labels, new_tokens, test_sentence)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'end': 46, 'entity': 'bimagrumab', 'start': 36, 'type': 'Gene'},\n",
              " {'end': 73,\n",
              "  'entity': 'inclusion body myositis',\n",
              "  'start': 50,\n",
              "  'type': 'Disease'},\n",
              " {'end': 159, 'entity': 'Bimagrumab', 'start': 149, 'type': 'Gene'},\n",
              " {'end': 254,\n",
              "  'entity': 'inclusion body myositis',\n",
              "  'start': 231,\n",
              "  'type': 'Disease'},\n",
              " {'end': 437,\n",
              "  'entity': 'inclusion body myositis',\n",
              "  'start': 414,\n",
              "  'type': 'Disease'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FT917tUbImC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_json = {\"text\": \"Safety and efficacy of intravenous bimagrumab in inclusion body myositis (RESILIENT): a randomised, double-blind, placebo-controlled phase 2b trial\\tBimagrumab showed a good safety profile, relative to placebo, in individuals with inclusion body myositis but did not improve 6MWD. The strengths of our study are that, to the best of our knowledge, it is the largest randomised controlled trial done in people with inclusion body myositis, and it provides important natural history data over 12 months.\", \"entities\": [{\"entity\": \"bimagrumab\", \"type\": \"Drug\", \"start\": 35, \"end\": 45}, {\"entity\": \"inclusion body myositis\", \"type\": \"Disease\", \"start\": 49, \"end\": 72}, {\"entity\": \"inclusion body myositis\", \"type\": \"Disease\", \"start\": 230, \"end\": 253}, {\"entity\": \"inclusion body myositis\", \"type\": \"Disease\", \"start\": 413, \"end\": 436}, {\"entity\": \"Bimagrumab\", \"type\": \"Drug\", \"start\": 148, \"end\": 158}, {\"entity\": \"6MWD\", \"type\": \"Gene\", \"start\": 274, \"end\": 278}, {\"entity\": \"pyrimidine nucleoside derivatives\", \"type\": \"ChemicalCompound\", \"start\": 273, \"end\": 306}]}\n",
        "\n",
        "json_str = json.dumps(test_json)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQcOOMVbb7PI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "012323c1-cc9b-4256-f2c7-85841ffba60d"
      },
      "source": [
        "print(json_str)\n",
        "with open('tem.json', 'w') as f:\n",
        "    json.dump(test_json, f, indent = 4)\n",
        "    json.dump({\"text\": test_sentence, \"entities\": label_to_dict(new_labels, new_tokens, test_sentence)}, f, indent = 4)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"text\": \"Safety and efficacy of intravenous bimagrumab in inclusion body myositis (RESILIENT): a randomised, double-blind, placebo-controlled phase 2b trial\\tBimagrumab showed a good safety profile, relative to placebo, in individuals with inclusion body myositis but did not improve 6MWD. The strengths of our study are that, to the best of our knowledge, it is the largest randomised controlled trial done in people with inclusion body myositis, and it provides important natural history data over 12 months.\", \"entities\": [{\"entity\": \"bimagrumab\", \"type\": \"Drug\", \"start\": 35, \"end\": 45}, {\"entity\": \"inclusion body myositis\", \"type\": \"Disease\", \"start\": 49, \"end\": 72}, {\"entity\": \"inclusion body myositis\", \"type\": \"Disease\", \"start\": 230, \"end\": 253}, {\"entity\": \"inclusion body myositis\", \"type\": \"Disease\", \"start\": 413, \"end\": 436}, {\"entity\": \"Bimagrumab\", \"type\": \"Drug\", \"start\": 148, \"end\": 158}, {\"entity\": \"6MWD\", \"type\": \"Gene\", \"start\": 274, \"end\": 278}, {\"entity\": \"pyrimidine nucleoside derivatives\", \"type\": \"ChemicalCompound\", \"start\": 273, \"end\": 306}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY7vr7CAeafl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e7f72e1-c568-4fff-c96b-26ee88d00533"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data  tem.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4sh8eh2ELOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "69656d55-884a-49e0-ad65-6a153849171f"
      },
      "source": [
        "#with open('tem.json', 'r') as f:\n",
        "#    tem = json.load(f)\n",
        "#    print(tem)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-3c1cde2fa4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tem.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 48 column 1 (char 1555)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4M7NaIA7X82",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate datasets from biendata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywZBP8y07XSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "cbc19723-3738-42e0-cc55-606433282cf2"
      },
      "source": [
        "import json\n",
        "\n",
        "input_dir = '/content/gdrive/My Drive/Covid19_data/'\n",
        "f_val = open(input_dir+'new_val.json','r')\n",
        "sentences = [] \n",
        "data = []\n",
        "for line in f_val:\n",
        "  sentence   = json.loads(line)['text']\n",
        "  sentences += [sentence]\n",
        "\n",
        "  oneline = sentence.split('.')\n",
        "  for sent in oneline:\n",
        "    if len(sent) == 0: continue\n",
        "    if sent[0]==' ': sent = sent[1:]\n",
        "    data.append(sent)\n",
        "\n",
        "data[:5]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Shared and distinct genetic risk factors for childhood-onset and adult-onset asthma: genome-wide and transcriptome-wide studies\\tGenetic risk factors for adult-onset asthma are largely a subset of the genetic risk for childhood-onset asthma but with overall smaller effects, suggesting a greater role for non-genetic risk factors in adult-onset asthma',\n",
              " 'Combined with gene expression and tissue enrichment patterns, we suggest that the establishment of disease in children is driven more by dysregulated allergy and epithelial barrier function genes, whereas the cause of adult-onset asthma is more lung-centred and environmentally determined, but with immune-mediated mechanisms driving disease progression in both children and adults',\n",
              " 'Spousal violence and potentially preventable single and recurrent spontaneous fetal loss in an African setting: cross-sectional study\\tSpousal violence increases the likelihood of single and repeated fetal loss',\n",
              " 'A large proportion of risk for recurrent fetal mortality is attributable to spousal violence and, therefore, is potentially preventable',\n",
              " 'Our findings support the idea of routine prenatal screening for spousal violence in the African setting, a region with the highest rate of fetal death in the world']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yM3EUvM7pPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_text = []\n",
        "for data0 in data:\n",
        "  return_texts = tokenizer.encode(data0)\n",
        "  eval_text.append(return_texts)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64XszEQX72cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "96412daa-ae57-4eff-a47e-352872e01467"
      },
      "source": [
        "text_len = []\n",
        "for txt in eval_text:\n",
        "  text_len.append(len(txt))\n",
        "\n",
        "plt.plot(text_len)\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAYJrs9G8MNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "32bf919c-b030-41f6-b591-a10451a4b7e5"
      },
      "source": [
        "MAX_LEN = 150\n",
        "eval_input_ids = pad_sequences(eval_text,\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "eval_input_ids[:2]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101,  4207,  1998,  5664,  7403,  3891,  5876,  2005,  5593,\n",
              "         1011, 14447,  1998,  4639,  1011, 14447, 26180,  1024, 13458,\n",
              "         1011,  2898,  1998, 24051,  8462,  1011,  2898,  2913,  7403,\n",
              "         3891,  5876,  2005,  4639,  1011, 14447, 26180,  2024,  4321,\n",
              "         1037, 16745,  1997,  1996,  7403,  3891,  2005,  5593,  1011,\n",
              "        14447, 26180,  2021,  2007,  3452,  3760,  3896,  1010,  9104,\n",
              "         1037,  3618,  2535,  2005,  2512,  1011,  7403,  3891,  5876,\n",
              "         1999,  4639,  1011, 14447, 26180,   102,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0],\n",
              "       [  101,  4117,  2007,  4962,  3670,  1998,  8153, 27226,  7060,\n",
              "         1010,  2057,  6592,  2008,  1996,  5069,  1997,  4295,  1999,\n",
              "         2336,  2003,  5533,  2062,  2011,  1040,  7274,  2890, 24848,\n",
              "         4383,  2035, 24395,  1998,  4958,  8939, 24587,  8803,  3853,\n",
              "         9165,  1010,  6168,  1996,  3426,  1997,  4639,  1011, 14447,\n",
              "        26180,  2003,  2062, 11192,  1011, 16441,  1998, 25262,  4340,\n",
              "         1010,  2021,  2007, 11311,  1011, 19872, 10595,  4439,  4295,\n",
              "        14967,  1999,  2119,  2336,  1998,  6001,   102,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ozCvP1UG6R_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37316332-ac1c-4a02-eb12-9df7f820cdd3"
      },
      "source": [
        "len(eval_input_ids)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20404"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt9DGey38QEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd7f38f2-963a-4b5c-d9ec-76f4e4049c78"
      },
      "source": [
        "eval_inputs = torch.tensor(eval_input_ids).cuda()\n",
        "print(len(eval_inputs), len(eval_inputs[0]))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20404 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPCb-Zzv8Sza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 32\n",
        "eval_data = TensorDataset(eval_inputs)\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=bs)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTFpsAok8YPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Put the model into evaluation mode\n",
        "model.eval()\n",
        "total_labels , total_tokens = [], []\n",
        "for batch in eval_dataloader:\n",
        "    b_input_ids = batch[0]\n",
        "    #print(b_input_ids)\n",
        "\n",
        "    # Telling the model not to compute or store gradients,\n",
        "    # saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # This will return the logits rather than the loss because we have not provided labels.\n",
        "        output = model(b_input_ids)\n",
        "    # Move logits and labels to CPU\n",
        "    label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "\n",
        "    # join bpe split tokens\n",
        "    tokens = tokenizer.convert_ids_to_tokens(b_input_ids.to('cpu').numpy()[0])\n",
        "    new_tokens, new_labels = [], []\n",
        "    for token, label_idx in zip(tokens, label_indices[0]):\n",
        "        if token.startswith(\"##\"):\n",
        "            new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "        else:\n",
        "            new_labels.append(tag_values[label_idx])\n",
        "            new_tokens.append(token)\n",
        "    total_labels += [new_labels]\n",
        "    total_tokens += [new_tokens]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY7-WZoSJHTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "907773de-1184-4f0e-b4c2-f81005711214"
      },
      "source": [
        "len(total_labels)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13FNhpyILsre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5869fe70-0a09-4103-fda1-b0b090b1bfa4"
      },
      "source": [
        "len(total_tokens)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "638"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApE-p9UEDa16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16996cac-21bf-460d-8c14-a0ab07ed3f52"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ95KW74FqCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f2e3883d-94df-4636-8d29-c4905f15c796"
      },
      "source": [
        "sentences[637]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"Efficiency and safety of varying the frequency of whole blood donation (INTERVAL): a randomised trial of 45\\u2008000 donors\\tOver 2 years, more frequent donation than is standard practice in the UK collected substantially more blood without having a major effect on donors' quality of life, physical activity, or cognitive function, but resulted in more donation-related symptoms, deferrals, and iron deficiency.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l1VJEFrF6cu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6f080c83-48ce-40d0-fbf3-4d875198e7bf"
      },
      "source": [
        "total_tokens[637]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'challenges',\n",
              " 'included',\n",
              " ':',\n",
              " 'difficulty',\n",
              " 'in',\n",
              " 'generalisation',\n",
              " 'because',\n",
              " 'of',\n",
              " 'scarce',\n",
              " 'and',\n",
              " 'context',\n",
              " '-',\n",
              " 'specific',\n",
              " 'health',\n",
              " '-',\n",
              " 'systems',\n",
              " 'knowledge',\n",
              " ';',\n",
              " 'no',\n",
              " 'consensus',\n",
              " 'for',\n",
              " 'optimum',\n",
              " 'service',\n",
              " '-',\n",
              " 'delivery',\n",
              " 'approaches',\n",
              " ',',\n",
              " 'leading',\n",
              " 'to',\n",
              " 'wide',\n",
              " 'cost',\n",
              " 'differences',\n",
              " ';',\n",
              " 'no',\n",
              " 'consensus',\n",
              " 'for',\n",
              " 'health',\n",
              " 'benefits',\n",
              " ';',\n",
              " 'difficulty',\n",
              " 'in',\n",
              " 'quantification',\n",
              " 'of',\n",
              " 'likely',\n",
              " 'efficiency',\n",
              " 'gains',\n",
              " ';',\n",
              " 'and',\n",
              " 'challenges',\n",
              " 'in',\n",
              " 'quantification',\n",
              " 'of',\n",
              " 'the',\n",
              " 'financing',\n",
              " 'gap',\n",
              " 'owing',\n",
              " 'to',\n",
              " 'uncertainties',\n",
              " 'about',\n",
              " 'financial',\n",
              " 'commitments',\n",
              " 'for',\n",
              " 'health',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FJsY9JD8dQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(input_dir+'output_new_val_0715.txt', 'w') as f:\n",
        "  for token, label in zip(total_tokens, total_labels):\n",
        "    print(token, label, file=f, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}